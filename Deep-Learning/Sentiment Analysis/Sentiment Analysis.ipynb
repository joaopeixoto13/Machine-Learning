{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc598aac",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3ee7b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds     # Import Tensorflow dataset that we will use\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "import os\n",
    "import mitdeeplearning as mdl\n",
    "from IPython import display as ipythondisplay\n",
    "from tqdm import tqdm\n",
    "\n",
    "tfds.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9483bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that we are using a GPU, if not switch runtimes\n",
    "#   using Runtime > Change Runtime Type > GPU\n",
    "len(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88233fd",
   "metadata": {},
   "source": [
    "# 2. Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "496e4483",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset, info = tfds.load('imdb_reviews', with_info=True,\n",
    "                          as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ee1d93",
   "metadata": {},
   "source": [
    "See one review and the output label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca746f83",
   "metadata": {},
   "source": [
    "Next shuffle the data for training and create batches of these (text, label) pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80227f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78d7e3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edd6d93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts:  [b\"First of all, I firmly believe that Norwegian movies are continually getting better. From the tedious emotional films of the 70's and 80's, movies from this place actually started to contain a bit of humour. Imagine.. Actual comedies were made! Movies were actually starting to get entertaining and funny, as opposed to long, dark, depressing and boring.<br /><br />During the 90's and 00's several really great movies were made by a 'new generation' of filmmakers. Movie after movie were praised by critics and played loads of money. It became the norm!<br /><br />Then came United...<br /><br />*MINOR SPOILERS* It's just simply not funny. Not once. Not ever. But the thing is... We THINK its funny. Because we're used to norwegian movies to be funny. Especially with a cast like this with a few really funny comedians. But.. They neither say nor do anything funny! Where's the humor? Show me the humor! Is it the awkward clerk played by Harald Eia? Is it the overacting totally ridiculously unrealistic football coach? Is it the commentaries by Arne Scheie? The movie is just not funny!<br /><br />But thats not my main rant about United. That namely is the predictability. (And it is here I fear that norwegian comedies have come to a standstill since I have seen this in many other movies as well.) All the time you just know its going to end well. All characters are exactly as they are presented in the start of the movie, and everybody gets exactly what they deserve in the end. There's absolutely no room for surprises at all!<br /><br />All in all I can say that I sat with a bad feeling after seeing this movie. It was the one movie that made me realize that we probably need some new blood in norwegian movie making... again!<br /><br />Rating: 1/6\"\n",
      " b\"This stirring western spins the tale of the famous rifle of the early west that was coveted by one and all. James Stewart is the cowboy who wins the prized Winchester in a shootout, only to lose it in a robbery. The story details Stewart's pursuit of the rifle and a certain man through the film. The rifle changes hands time after time, as though the owner is fated to lose it through violence. The picture has plenty of action and suspense as Stewart closes in on his quarry. A great cast supports Stewart here, namely Stephen McNally, Dan Duryea, Millard Mitchell, John McIntire and Jay C. Flippen. Shelley Winters seems miscast here and the purpose of her role is rather obscure. Tony Curtis and Rock Hudson, teen heartthrobs in later years, have brief but good roles.\"]\n",
      "\n",
      "labels:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "  print('texts: ', example.numpy()[:2])\n",
    "  print()\n",
    "  print('labels: ', label.numpy()[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6857d4",
   "metadata": {},
   "source": [
    "# 3. Encode / Vectorize the text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10035c71",
   "metadata": {},
   "source": [
    "Capture all Reviews and Labels from the Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9e96a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "labels = []\n",
    "for i, [review, label] in enumerate(train_dataset):\n",
    "    for j in range(len(review)):\n",
    "        reviews.append(review.numpy()[j].decode('utf-8').lower())\n",
    "        labels.append(label.numpy()[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720a9cdf",
   "metadata": {},
   "source": [
    "See one example of one specific Review and the corresponde Label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb990e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "giant crabs cursing in japanese? what was in that drink? a terrible movie, but laughable. i love the invisible samurai ghosties running around. drink much beer before you see this movie.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(reviews[22000])\n",
    "print(labels[22000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15512026",
   "metadata": {},
   "source": [
    "Create a function that encode the text to a list of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d783086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_text(text):\n",
    "    words = text.split()                                           # Split into words\n",
    "    words = [word.strip('.,!;()''[]\"#&%*@/Â£$') for word in words]  # Remove punctuation marks\n",
    "    words = [word.replace(\"'s\", '') for word in words]             # Remove 's\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8f4d02",
   "metadata": {},
   "source": [
    "Apply the function to all Reviews and create a nester list that eache row contains one list of words that each review: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9b765f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for i, review in enumerate(reviews):\n",
    "    words.append(vectorized_text(review))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91392a21",
   "metadata": {},
   "source": [
    "See one example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4dab78a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['giant', 'crabs', 'cursing', 'in', 'japanese?', 'what', 'was', 'in', 'that', 'drink?', 'a', 'terrible', 'movie', 'but', 'laughable', 'i', 'love', 'the', 'invisible', 'samurai', 'ghosties', 'running', 'around', 'drink', 'much', 'beer', 'before', 'you', 'see', 'this', 'movie']\n"
     ]
    }
   ],
   "source": [
    "print(words[22000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a79e7b",
   "metadata": {},
   "source": [
    "Now lets convert to one only list the words nester list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2064c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_words = []\n",
    "for elem in words:\n",
    "    flat_words.extend(elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b557c616",
   "metadata": {},
   "source": [
    "Create a function that allows us create one dictionary of all unique words presents on dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "197ecbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_words(words):\n",
    "    unique_words_dict = {}\n",
    "    u_words = list(set(words))\n",
    "    u_words.sort()\n",
    "    for i, word in enumerate(u_words):\n",
    "        unique_words_dict.update({word: i})\n",
    "    return unique_words_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633efb08",
   "metadata": {},
   "source": [
    "Apply the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8bc254ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words_dict = unique_words(flat_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a50178",
   "metadata": {},
   "source": [
    "See how many unique words we have in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f154b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147916\n"
     ]
    }
   ],
   "source": [
    "print(len(unique_words_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745fdd9f",
   "metadata": {},
   "source": [
    "Show the first pairs of key and values of our Dictionary of unique words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf631a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0\n",
      "\b\b\b\ba 1\n",
      "\u0010own 2\n",
      "' 3\n",
      "'' 4\n",
      "''<br 5\n",
      "''a 6\n",
      "''after 7\n",
      "''bad 8\n",
      "''cannibal 9\n",
      "''clients'' 10\n",
      "''dark'' 11\n",
      "''empire 12\n",
      "''family 13\n",
      "''gaslight'' 14\n",
      "''heart'' 15\n",
      "''high 16\n",
      "''holy 17\n",
      "''human'' 18\n",
      "''humans'' 19\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for review, label in unique_words_dict.items():\n",
    "    print(review, label)\n",
    "    count += 1\n",
    "    if count % 20 == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0cfc3e",
   "metadata": {},
   "source": [
    "Create the `Encode Function`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "423e9786",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {u:i for i, u in enumerate(unique_words_dict)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c776b94",
   "metadata": {},
   "source": [
    "Create the `Decoder Function`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7599dd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx2word(idx):\n",
    "    key_list = list(unique_words_dict.keys())\n",
    "    val_list = list(unique_words_dict.values())\n",
    "    position = val_list.index(idx)\n",
    "    return key_list[position]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be53b54",
   "metadata": {},
   "source": [
    "Create the **Encoder Function** that will encode all words presents in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "858c6a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(words):\n",
    "  encoded_output = np.array([word2idx[word] for word in words])\n",
    "  return encoded_output\n",
    "\n",
    "encoded_words = encode(flat_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f548290",
   "metadata": {},
   "source": [
    "Let's see one exemple of vectorized string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "924f2314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three', 'stooges', '-', 'have', 'rocket', 'will', 'travel', '-', '1959', 'this'] ---- characters mapped to int ----> [132501 126058   3381  65636 113004 144177 135072   3381   4749 132157]\n"
     ]
    }
   ],
   "source": [
    "print ('{} ---- characters mapped to int ----> {}'.format(repr(flat_words[:10]), encoded_words[:10]))\n",
    "# check that vectorized_songs is a numpy array\n",
    "assert isinstance(encoded_words, np.ndarray), \"returned result should be a numpy array\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09c40b2",
   "metadata": {},
   "source": [
    "Compare the results to check if is all alright:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b314950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143400\n",
      "55385\n",
      "131388\n"
     ]
    }
   ],
   "source": [
    "print(unique_words_dict['what'])\n",
    "print(unique_words_dict['film'])\n",
    "print(unique_words_dict['the'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c0d088",
   "metadata": {},
   "source": [
    "# 4. Create training examples and targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9f4f4b",
   "metadata": {},
   "source": [
    "First we need to create a nester list for our reviews words already encoded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96338b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_encoded = []\n",
    "\n",
    "for i in range(len(words)):\n",
    "    reviews_encoded.append(encode(words[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02abe158",
   "metadata": {},
   "source": [
    "See one example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adbc5671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[125688  68029  13455  63316  58644  67172 116071  57297  13455 111820\n",
      "  20400 131388  29735  81687 143548  67698 136385  28376 143270 143201\n",
      "  88613 143599 131832  19343 131720  13455 111233  39159  71254 131388\n",
      " 118938  95863  13455  84209  86114  13455  82292  95863 131388  60895\n",
      "  58644  39159  58644 131388  25409  78654  71254 131388 144136  33486\n",
      " 131388 112423 133019 133534 102033 131479  18775  96711  29550  96711\n",
      "  13455  25026  49309 112611 133019  54839  21952  76505  85381  17537\n",
      " 137580  87818  29056 119090 104656  52613  71254 143599  73955  16954\n",
      " 118325  19937  13455 102609  95863 114572  58644 131388 131925  96544\n",
      " 131388  25991 108363  76504  77836  89729 131231 119090 130669  16954\n",
      " 127671 131388  82260  95863  13455  33168  29369 131720  18181  94888\n",
      " 136408  90001  95863 131388  63316  65636  93718  70311  95863 132157\n",
      "  39159  87692  76050  23275  89729  69532 131231 131832 109410  73955\n",
      "  57635  70377  87692 119133 122907  80808  96544  13455  41935  96976\n",
      "  96711  97753 101381  65440  23723  67149 120718 143271  41693  76504\n",
      "  68092 131388  76862 133534  84623  95863 131388  91788 131270 138276\n",
      "  19937 131388  63316 110740  92541 131388  29736   7945  12279  13455\n",
      "  79027 104080  95863 131388  55385 125427  21241  58644 131388  39159\n",
      " 143580  79697  71254 131388  15971 143599 142501  16954 117137  13455\n",
      "  65772 116491 143533 142501  82029 132652  73955  53076 131388  55385\n",
      "  65440  41379  39257  86721 143580  96149  67572  18608 109293 130851\n",
      " 131270  92723 133534  28836  71254  13455  81438  89426  90321 131388\n",
      "  44404  73674 140157  25605  79653 133534  13455 110570  47610  52573\n",
      "  72609  95863  49249 115680 131388  31291  73674 108685  80697  17653\n",
      " 138134 105372  83656  62426  57027 110749  87692  23275 131388  96976\n",
      "  46924  57297 132157  55385]\n",
      "0\n",
      "------------\n",
      "[ 70123 115443 132157  90321 109693   5069  69120  79211  91724  65822\n",
      " 125803  69841  58644  79371 131388 103108 141997 123169  21308 131388\n",
      "  75566 143215 123169  21918  29369 143400  70123  43922  38433  96544\n",
      " 143233   7945   7798 131388   5069 115864  23786  17653  15467 131388\n",
      "  90321 131270  64157 100216  17653  74897 104146 131270  31640  89729\n",
      " 131231  50351  79408   7945   7838 131388  76971 132652 131388 144367\n",
      " 131270  41883 131388  51820   7945  12328  90321  73674  13799   5179\n",
      " 133226  24639 131231 131388 114140  69099 118212  17653  91724  37956\n",
      "  51532  30081 144631  13455  44765 115531  70471 146781  43922  80900\n",
      " 131388  90321 117873  31999 133534  65781 143599  70123  37212  73955\n",
      " 131388  41242 146781  64157 133534 117873  73955  71254 141997  74764\n",
      "   4980 143580  16954  31640 141353 133534  50439]\n",
      "1\n",
      "------------\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(reviews_encoded[22397])\n",
    "print(labels[22397])\n",
    "print(\"------------\")\n",
    "print(reviews_encoded[8278])\n",
    "print(labels[8278])\n",
    "print(\"------------\")\n",
    "print(len(reviews_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b337d398",
   "metadata": {},
   "source": [
    "Now we must create a function that will help us find the `max columns` presents in one batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7b20d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_columns(reviews_encoded):\n",
    "    max_col = 0\n",
    "    for i, k in enumerate(reviews_encoded):\n",
    "        j = len(reviews_encoded[i])\n",
    "        if j > max_col:\n",
    "            max_col = j\n",
    "    return max_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a14f9e",
   "metadata": {},
   "source": [
    "Our next step is create a batch of training examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "957bac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(reviews_encoded, labels, batch_size):\n",
    "    \n",
    "    # the length of the vectorized songs string\n",
    "    n = len(reviews_encoded)\n",
    "    \n",
    "    # randomly choose the starting indices for the examples in the training batch\n",
    "    # choose in [0, n] range 'batch_size' numbers randomly\n",
    "    idx = np.random.choice(n, batch_size)\n",
    "    \n",
    "    # List of input sequences for the training batch\n",
    "    input_batch = []\n",
    "    for i in idx:\n",
    "        input_batch.append(reviews_encoded[i])\n",
    "    \n",
    "    # List of output sequences for the training output\n",
    "    output_batch = []\n",
    "    for i in idx:\n",
    "        output_batch.append(labels[i])\n",
    "    \n",
    "    # Find the max columns on the input batch\n",
    "    max_col = max_columns(input_batch)\n",
    "    \n",
    "    # Padding with the most frequently word (\"the\") to ensure the columns have the same size\n",
    "    for i, j in enumerate(input_batch):\n",
    "        input_batch[i] = np.pad(input_batch[i], (0, (max_col - len(input_batch[i]))), constant_values=unique_words_dict['the'])\n",
    "       \n",
    "    # Reshape the output_batch\n",
    "    for i, j in enumerate(output_batch):\n",
    "        output_batch[i] = np.expand_dims(output_batch[i], axis=0)\n",
    "        \n",
    "    for i, j in enumerate(output_batch):\n",
    "        output_batch[i] = np.pad(output_batch[i], (0, max_col - 1), constant_values=output_batch[i][0])\n",
    "    \n",
    "    # x_batch, y_batch provide the true inputs and targets for network training\n",
    "    # rows: batch_size\n",
    "    # colm: None (variable seq.length)\n",
    "    x_batch = np.reshape(input_batch, [batch_size, max_col])\n",
    "    y_batch = np.reshape(output_batch, [batch_size, max_col])\n",
    "    \n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc40afa",
   "metadata": {},
   "source": [
    "Test our get_batch function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ebb5e57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   0\n",
      "  input: [146561  70123  43880  19937  70123 120974  66702 109940 110827  65674] ...\n",
      "  expected output: [1 1 1 1 1 1 1 1 1 1] ...\n",
      "Step   1\n",
      "  input: [ 70137  13455 145759 145292  20400  68267  17653  43691  91351  73674] ...\n",
      "  expected output: [1 1 1 1 1 1 1 1 1 1] ...\n",
      "Step   2\n",
      "  input: [ 70123 109233 122442  84623  36074 131270  70123 133941 118973  13799] ...\n",
      "  expected output: [1 1 1 1 1 1 1 1 1 1] ...\n",
      "Step   3\n",
      "  input: [132157 104226  37392 124274   6934   7945  10062  94564  13455  24922] ...\n",
      "  expected output: [0 0 0 0 0 0 0 0 0 0] ...\n"
     ]
    }
   ],
   "source": [
    "x_batch, y_batch = get_batch(reviews_encoded, labels=labels, batch_size=4)\n",
    "for i, (input_idx, target_idx) in enumerate(zip(np.squeeze(x_batch), np.squeeze(y_batch))):\n",
    "    print(\"Step {:3d}\".format(i))\n",
    "    print(\"  input: {} ...\".format(input_idx[:10]))\n",
    "    print(\"  expected output: {} ...\".format(target_idx[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94964f4d",
   "metadata": {},
   "source": [
    "# 5. Create the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef544265",
   "metadata": {},
   "source": [
    "First we go create the LSTM function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "83c772ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM(rnn_units):\n",
    "    return tf.keras.layers.LSTM(\n",
    "    rnn_units, \n",
    "    return_sequences=True, \n",
    "    recurrent_initializer='glorot_uniform',\n",
    "    recurrent_activation='sigmoid',\n",
    "    stateful=True,\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a13cbd",
   "metadata": {},
   "source": [
    "Create the Function that create all Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3a468160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    \n",
    "  model = tf.keras.Sequential([\n",
    "      \n",
    "    # Layer 1: Embedding layer to transform indices into dense vectors of a fixed embedding size\n",
    "    tf.keras.layers.Embedding(vocab_size, \n",
    "                              embedding_dim,\n",
    "                              # Use masking to handle the variable sequence lengths\n",
    "                              mask_zero=True,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "\n",
    "    # Layer 2: Bidirectional LSTM with `rnn_units` number of units \n",
    "    # Forward and backwards through the RNN layer and then concatenates the final output) \n",
    "    # Call the function previously created\n",
    "    tf.keras.layers.Bidirectional(LSTM(rnn_units)), \n",
    "\n",
    "    # Layer 3: Dense (fully-connected) layer that transforms the LSTM output into the vocabulary size \n",
    "    # (responsable to predict next character) \n",
    "    tf.keras.layers.Dense(batch_size, activation='relu'),\n",
    "      \n",
    "    tf.keras.layers.Dense(1),\n",
    "      \n",
    "    # Flatt our result\n",
    "    tf.keras.layers.Flatten()\n",
    "  ])\n",
    "\n",
    "  return model\n",
    "\n",
    "# Build a simple model with default hyperparameters.  \n",
    "model = build_model(vocab_size=len(unique_words_dict), embedding_dim=256 ,rnn_units=64, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7302aa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (64, None, 256)           37866496  \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (64, None, 128)           164352    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (64, None, 64)            8256      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (64, None, 1)             65        \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (64, None)                0         \n",
      "=================================================================\n",
      "Total params: 38,039,169\n",
      "Trainable params: 38,039,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5bebd221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1051)\n",
      "(64, 1051)\n",
      "Input shape:       (64, 1051)     # (batch_size, sequence_length)\n",
      "Prediction shape:  (64, 1051)  # (batch_size, sequence_length, 1)\n"
     ]
    }
   ],
   "source": [
    "x, y = get_batch(reviews_encoded, labels=labels, batch_size=64)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "pred = model(x)\n",
    "print(\"Input shape:      \", x.shape, \"    # (batch_size, sequence_length)\")\n",
    "print(\"Prediction shape: \", pred.shape, \" # (batch_size, sequence_length, 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2898ca1",
   "metadata": {},
   "source": [
    "# 6. Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c72ff6",
   "metadata": {},
   "source": [
    "First we need create the Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9bc8bedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1051)\n",
      "(64, 1051)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7805519c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 1051)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       0.6893809\n"
     ]
    }
   ],
   "source": [
    "# Receive the labels and the predictions (logits)\n",
    "def compute_loss(labels, logits):\n",
    "  loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "  return loss(labels, logits)\n",
    "\n",
    "example_batch_loss = compute_loss(y, pred)\n",
    "\n",
    "print(\"Prediction shape: \", pred.shape, \" # (batch_size, sequence_length, vocab_size)\") \n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffddb463",
   "metadata": {},
   "source": [
    "Training Operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6805a0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization parameters\n",
    "num_training_iterations = 2000  # Increase this to train longer\n",
    "batch_size = 4                  # Experiment between 1 and 64\n",
    "learning_rate = 5e-3            # Experiment between 1e-5 and 1e-1\n",
    "\n",
    "# Model parameters \n",
    "vocab_size = len(unique_words_dict)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024                # Experiment between 1 and 2048\n",
    "\n",
    "# Checkpoint location \n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"my_ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1f2599",
   "metadata": {},
   "source": [
    "Define Optimizer and Training Operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3311063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Model\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
    "\n",
    "# Instantiate an Optimizer with its Learning Rate.\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y): \n",
    "  \n",
    "  with tf.GradientTape() as tape:\n",
    "  \n",
    "    # Feed the current input into the model and generate predictions\n",
    "    y_hat = model(x)\n",
    "  \n",
    "    # Compute the Loss\n",
    "    loss = compute_loss(y, y_hat) \n",
    "\n",
    "  # Now, compute the gradients \n",
    "  '''complete the function call for gradient computation. \n",
    "      Remember that we want the gradient of the loss with respect all \n",
    "      of the model parameters. \n",
    "      HINT: use `model.trainable_variables` to get a list of all model\n",
    "      parameters.'''\n",
    "  grads = tape.gradient(loss, model.trainable_variables)\n",
    "  \n",
    "  # Apply the gradients to the optimizer so it can update the model accordingly\n",
    "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a08610",
   "metadata": {},
   "source": [
    "Begin Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "10850ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:38<2:06:35,  3.82s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-174-4d6aa10981a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m   \u001b[1;31m# Grab a batch and propagate it through the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m   \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews_encoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m   \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m   \u001b[1;31m# Update the progress bar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m-> 3038\u001b[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    981\u001b[0m           \u001b[1;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m           \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 983\u001b[1;33m             return autograph.converted_call(\n\u001b[0m\u001b[0;32m    984\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\tmpbmwm4cri.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                     \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;34m'complete the function call for gradient computation. \\n      Remember that we want the gradient of the loss with respect all \\n      of the model parameters. \\n      HINT: use `model.trainable_variables` to get a list of all model\\n      parameters.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    334\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Allowlisted %s: from cache'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    462\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    367\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[1;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m     \"\"\"\n\u001b[1;32m--> 414\u001b[1;33m     return self._run_internal_graph(\n\u001b[0m\u001b[0;32m    415\u001b[0m         inputs, training=training, mask=mask)\n\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\keras\\layers\\wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[1;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\keras\\layers\\wrappers.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask, initial_state, constants)\u001b[0m\n\u001b[0;32m    696\u001b[0m         \u001b[0mforward_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackward_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 698\u001b[1;33m       y = self.forward_layer(forward_inputs,\n\u001b[0m\u001b[0;32m    699\u001b[0m                              initial_state=forward_state, **kwargs)\n\u001b[0;32m    700\u001b[0m       y_rev = self.backward_layer(backward_inputs,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1037\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m   1251\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m           (last_output, outputs, new_h, new_c,\n\u001b[1;32m-> 1253\u001b[1;33m            runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\n\u001b[0m\u001b[0;32m   1254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m       \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_c\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mlstm_with_backend_selection\u001b[1;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[1;31m# grappler will kick in during session execution to optimize the graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1648\u001b[0m     \u001b[0mlast_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mruntime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefun_standard_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1649\u001b[1;33m     \u001b[0m_function_register\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefun_gpu_lstm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1651\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mlast_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mruntime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36m_function_register\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m   \u001b[0mconcrete_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1782\u001b[0m   \u001b[0mconcrete_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1783\u001b[1;33m   \u001b[0mconcrete_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_gradient_functions_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1784\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mconcrete_func\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36madd_gradient_functions_to_graph\u001b[1;34m(self, g)\u001b[0m\n\u001b[0;32m   2100\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2101\u001b[0m     forward_function, backward_function = (\n\u001b[1;32m-> 2102\u001b[1;33m         self._delayed_rewrite_functions.forward_backward())\n\u001b[0m\u001b[0;32m   2103\u001b[0m     \u001b[0mforward_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2104\u001b[0m     \u001b[0mbackward_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mforward_backward\u001b[1;34m(self, num_doutputs)\u001b[0m\n\u001b[0;32m    691\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mforward_backward\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mforward_backward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m     \u001b[0mforward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_forward_backward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_function_pairs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_construct_forward_backward\u001b[1;34m(self, num_doutputs)\u001b[0m\n\u001b[0;32m    734\u001b[0m       backwards_graph = func_graph_module.FuncGraph(\n\u001b[0;32m    735\u001b[0m           _backward_name(self._func_graph.name))\n\u001b[1;32m--> 736\u001b[1;33m       func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m    737\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbackwards_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m           \u001b[0mpython_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_backprop_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_backprop_function\u001b[1;34m(*grad_ys)\u001b[0m\n\u001b[0;32m    725\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_backprop_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         return gradients_util._GradientsHelper(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    728\u001b[0m             \u001b[0mtrainable_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    679\u001b[0m                 \u001b[1;31m# If grad_fn was found, do not use SymbolicGradient even for\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0m\u001b[0;32m    682\u001b[0m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0;32m    683\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Exit early\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m   \u001b[1;31m# If the gradients are supposed to be compiled separately, we give them a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    680\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 682\u001b[1;33m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[0;32m    683\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m                 \u001b[1;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\ops\\cond_v2.py\u001b[0m in \u001b[0;36m_IfGrad\u001b[1;34m(op, *grads)\u001b[0m\n\u001b[0;32m    123\u001b[0m   true_grad_graph = _create_grad_func(\n\u001b[0;32m    124\u001b[0m       true_graph, grads, util.unique_grad_fn_name(true_graph.name))\n\u001b[1;32m--> 125\u001b[1;33m   false_grad_graph = _create_grad_func(\n\u001b[0m\u001b[0;32m    126\u001b[0m       false_graph, grads, util.unique_grad_fn_name(false_graph.name))\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\ops\\cond_v2.py\u001b[0m in \u001b[0;36m_create_grad_func\u001b[1;34m(func_graph, grads, name)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_create_grad_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m   \u001b[1;34m\"\"\"Returns the FuncGraph representation of _grad_fn.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m   return func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m    393\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m       \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_grad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\ops\\cond_v2.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    392\u001b[0m   return func_graph_module.func_graph_from_py_func(\n\u001b[0;32m    393\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m       \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_grad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m       func_graph=_CondGradFuncGraph(name, func_graph))\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\ops\\cond_v2.py\u001b[0m in \u001b[0;36m_grad_fn\u001b[1;34m(func_graph, grads)\u001b[0m\n\u001b[0;32m    381\u001b[0m   \u001b[1;31m# func_graph. The captured func_graph tensors are resolved to external tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m   \u001b[1;31m# in _resolve_grad_inputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m   result = gradients_util._GradientsHelper(\n\u001b[0m\u001b[0;32m    384\u001b[0m       \u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m       src_graph=func_graph)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    679\u001b[0m                 \u001b[1;31m# If grad_fn was found, do not use SymbolicGradient even for\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0m\u001b[0;32m    682\u001b[0m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0;32m    683\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Exit early\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m   \u001b[1;31m# If the gradients are supposed to be compiled separately, we give them a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    680\u001b[0m                 \u001b[1;31m# functions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 682\u001b[1;33m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[0;32m    683\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m                 \u001b[1;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py\u001b[0m in \u001b[0;36m_WhileGrad\u001b[1;34m(op, *grads)\u001b[0m\n\u001b[0;32m    379\u001b[0m       body_graph.outputs, body_graph.inputs, grads) if grad is not None])\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m   body_grad_graph, args = _create_grad_func(\n\u001b[0m\u001b[0;32m    382\u001b[0m       \u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_none_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcond_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m       \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique_grad_fn_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaximum_iterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py\u001b[0m in \u001b[0;36m_create_grad_func\u001b[1;34m(ys, xs, grads, cond_graph, body_graph, name, while_op, maximum_iterations, stateful_parallelism)\u001b[0m\n\u001b[0;32m    678\u001b[0m   \u001b[1;31m# Note: The returned function does not have `args` in the list of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m   \u001b[1;31m# `external_captures`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m   grad_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m    681\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m       \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_grad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    680\u001b[0m   grad_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0;32m    681\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m       \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_grad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m       func_graph=_WhileBodyGradFuncGraph(name, cond_graph, body_graph,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py\u001b[0m in \u001b[0;36m_grad_fn\u001b[1;34m(ys, xs, args, func_graph)\u001b[0m\n\u001b[0;32m    736\u001b[0m   \u001b[1;31m# after the forward While op has been rewritten in _resolve_grad_captures.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m   \u001b[1;31m# TODO(srbs): Mark GradientsHelper as public?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 738\u001b[1;33m   grad_outs = gradients_util._GradientsHelper(\n\u001b[0m\u001b[0;32m    739\u001b[0m       \u001b[0mys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad_ys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m       unconnected_gradients=\"zero\")\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mloop_state\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m           \u001b[0mloop_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnterGradWhileContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbefore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m         out_grads = _AggregatedGrads(grads, op, gradient_uid, loop_state,\n\u001b[0m\u001b[0;32m    592\u001b[0m                                      aggregation_method)\n\u001b[0;32m    593\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mloop_state\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_AggregatedGrads\u001b[1;34m(grads, op, gradient_uid, loop_state, aggregation_method)\u001b[0m\n\u001b[0;32m    998\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m           \u001b[0mused\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"add_n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1000\u001b[1;33m           \u001b[0mout_grads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_MultiDeviceAddN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient_uid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1001\u001b[0m         logging.vlog(2, \"  _AggregatedGrads %d x %s using %s\", len(out_grad),\n\u001b[0;32m   1002\u001b[0m                      tensor_shape, used)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\u001b[0m in \u001b[0;36m_MultiDeviceAddN\u001b[1;34m(tensor_list, gradient_uid)\u001b[0m\n\u001b[0;32m    884\u001b[0m         \u001b[0mgradient_uid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m         ignore_existing=True):\n\u001b[1;32m--> 886\u001b[1;33m       \u001b[0msummands\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_n\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_n\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummands\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36madd_n\u001b[1;34m(inputs, name)\u001b[0m\n\u001b[0;32m   3998\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3999\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4000\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_n\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4001\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4002\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36madd_n\u001b[1;34m(inputs, name)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \"'add_n' Op, not %r.\" % inputs)\n\u001b[0;32m    399\u001b[0m   \u001b[0m_attr_N\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[0;32m    401\u001b[0m         \"AddN\", inputs=inputs, name=name)\n\u001b[0;32m    402\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    746\u001b[0m       \u001b[1;31m# Add Op to graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[0;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   1027\u001b[0m           compute_device=compute_device)\n\u001b[0;32m   1028\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m     return super(_WhileBodyGradFuncGraph, self)._create_op_internal(\n\u001b[0m\u001b[0;32m   1030\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    600\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m         compute_device)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3559\u001b[0m     \u001b[1;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3560\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3561\u001b[1;33m       ret = Operation(\n\u001b[0m\u001b[0;32m   3562\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3563\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2039\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2040\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2041\u001b[1;33m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[0;32m   2042\u001b[0m                                 control_input_ops, op_def)\n\u001b[0;32m   2043\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_2.5\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1879\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1880\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1881\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = []\n",
    "plotter = mdl.util.PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Loss')\n",
    "\n",
    "if hasattr(tqdm, '_instances'): tqdm._instances.clear()  # clear if it exists\n",
    "\n",
    "for iter in tqdm(range(num_training_iterations)):\n",
    "\n",
    "  # Grab a batch and propagate it through the network\n",
    "  x_batch, y_batch = get_batch(reviews_encoded, labels, batch_size)\n",
    "  loss = train_step(x_batch, y_batch)\n",
    "\n",
    "  # Update the progress bar\n",
    "  history.append(loss.numpy().mean())\n",
    "  plotter.plot(history)\n",
    "\n",
    "  # Update the model with the changed weights!\n",
    "  if iter % 100 == 0:     \n",
    "    model.save_weights(checkpoint_prefix)\n",
    "    \n",
    "# Save the trained model and the weights\n",
    "model.save_weights(checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43dbfb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
